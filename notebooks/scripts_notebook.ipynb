{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n"]}],"source":["print(1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import ir_datasets\n","import email\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n","import gc\n","from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n","from config import *\n","import re\n","import numpy as np"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Data set-up, pre-processing and model set-up, evaluation metrics, experiment set-up"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append(\"../scripts/\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from dataset import load_sara\n","from eval import jupyter_evaluation\n","from model import llm_experiment, post_process_split_docs\n","from models import get_model_version\n","from preprocess_sara import proccutit\n","\n","\n","#s = load_sara()\n","#proc = proccutit(s)\n","#tokenizer, model = get_model_version('get_mistral', \"mistralai/Mistral-7B-Instruct-v0.2\", 'main', 'auto')\n","#jupyter_evaluation(labels, preds)\n","#llm_experiment(dataset, prompt_strategy, model, tokenizer, end_prompt=None):\n","#post_process_split_docs(mr, fpr, pre, df)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.58s/it]\n"]}],"source":["tokenizer, model = get_model_version('get_mistral', \"mistralai/Mistral-7B-Instruct-v0.2\")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def get_sample_n(data, n):\n","    return data.sample(n=n, random_state=1)\n","\n","def get_sample_frac(data, frac):\n","    return data.sample(frac=frac, random_state=1)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Main experiment - main call"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["# Get dataset\n","# Preprocess\n","# Get model\n","# Get prompt\n","# Run evaluation\n","# Display evaluation metrics\n","\n","def main_experiment(portion, portion_value, proc_meth, prompt_strategy, end_prompt, tokenizer, model):\n","    sara_df = load_sara()\n","    if portion == 'n':\n","        samp = get_sample_n(sara_df, portion_value)\n","    else:\n","        samp = get_sample_frac(sara_df, portion_value)\n","\n","    if proc_meth:\n","        proc_samp = proccutit(samp)\n","    else:\n","        proc_samp = samp\n","        \n","    #tokenizer, model = get_model_version(m, v)\n","    preds, truths, model_responses, further_processing_required = llm_experiment(proc_samp, prompt_strategy, model, tokenizer, end_prompt)\n","    new_preds, new_truths = post_process_split_docs(model_responses, further_processing_required, preds, sara_df)\n","    jupyter_evaluation(new_truths, new_preds)\n","    return model_responses"]},{"cell_type":"markdown","metadata":{},"source":["### Investigation"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def post_process_classification(classification):\n","    match_string = classification.lower()\n","    if \"non-personal\" in match_string:\n","        return 0\n","    elif \"personal\" in match_string:\n","        return 1\n","    else:\n","        return None"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["def b1(document):\n","  return f\"[INST] Your task is to determine if the email message from a work email contains personal information. Purely personal messages include personal information and do not include any relation to work being done. Personal but in a professional context messages include personal information that are related to work, for example comments about the quality of people's work and expressions of feelings about employee treatment. Does the message contain purely personal information or information that is personal a professional context? \\nMessage: {document} \\n[/INST] \\n The text does\"\n","\n","def b1(document):\n","  return f\"[INST] Your task is to determine if the email message from a work email contains personal information. Purely personal messages include personal information and do not include any relation to work being done. Personal but in a professional context messages include personal information that are related to work, for example comments about the quality of people's work and expressions of feelings about employee treatment. Does the message contain purely personal information or information that is personal a professional context? If the message does contain personal information respond with 'personal', otherwise respond with 'non-personal'. \\nMessage: {document} \\n[/INST] \\nClassification: \"\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#mr = main_experiment('n', 10, True, b1, '\\n[/INST]', tokenizer, model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
