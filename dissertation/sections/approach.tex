\section{Task/Approach}
\subsection{Sensitive information within emails}
We focus on exploring the automatic classification of sensitive personal information in emails using generative LLMs. Identifying sensitive personal information is an important task, and previous work (discussed in Related Work (Section \ref{sec:background})) has aimed to classify this sensitivity as this is the most prominent exemption that prevents a document from release in the UK \cite{TNA:16}. Interviews by Iqbal et al. reveal interviewees are often concerned about the intermixing of private conversations and work emails \cite{iqbal2021search}. It is easy to accidentally reveal sensitive personal information within work emails as we share private information between our closest colleagues. Therefore, we use email documents as emails contain sensitive information about our personal lives. Automatic sensitivity classifiers could efficiently and safely inspect emails and remove any containing sensitive personal information. Accessing email collections would also be useful for archives interested in storing information from government, universities and businesses for future research. However, currently email collections are rarely regularly collected by archives due to privacy concerns and the volume of documents in an email collection \cite{TFTAEA:18}. Improved sensitivity identification methods will allow archivists to open email collections while respecting the privacy of email authors, motivating our exploration of generative LLMs and prompting strategies to identify sensitive personal information within emails.

We use a public email collection, Enron \cite{klimt2004enron}, which was released during a legal investigation of the company’s collapse in 2001. This collection contains 619,446 company email messages. A subset of 1702 email threads was annotated by students at UC Berkeley for relevance to eight coarse genres present in work emails \cite{hearst2005teaching}. These genres include Company Business and Strategy, Purely Personal, Personal but in Professional Context, Logistic Arrangements (such as meeting scheduling and technical support), Employment Arrangements, Document Collaboration, Empty Message (sending attachment), and Empty message (forwarded messages)). Consequently, we believe our findings can be applied to other email collections in professional settings.

McKechnie et al. produce SARA \cite{mckechnie2024sara}, a collection of sensitivity-aware relevance assessments for UC Berkeley’s Enron subset. McKechnie et al. use the coarse genres `purely personal' which contain emails with no relation to work and discusses personal affairs, and `personal but in a professional context' which contains emails that do have relation to work being done at Enron but discusses individual’s quality of work and personal opinions about employee treatment, to produce sensitivity labels for sensitive personal information. SARA’s 1702 documents have 211 sensitive documents, 1491 non-sensitive documents, and is accessible through python package `IR datasets' \cite{macavaney2021simplified}. \\\\

\subsection{Model use in sensitivity classification}
Generative pre-trained LLMs are effective zero-shot learners \cite{kojima2022large}. The benefit of zero-shot learning means we can have effective inference without the cost of fine-tuning. In our classification task, we configure the model to generate a class of interest which is not the primary focus during the pre-training stage. Our investigation plans to evaluate if LLMs can successfully generate the sensitive or non-sensitive class for a given document. Therefore, we investigate if LLMs are effective without any training as this suggests these pre-trained generative models will be useful in other sensitive domains. A limitation when using pretrained LLMs is that their training data will have included biases that are unwanted for assessing potentially sensitive documents. However, the large training process that comes with language models of this size means it is difficult to ensure all training is completed with unbiased data.

Recent generative LLMs, such as OpenAI’s GPT-4 model \cite{openai2023gpt}, show great advancements on NLP benchmarks, showcasing the advanced reasoning capabilities of LLMs. However, accessing OpenAI’s newest and high-performance models have a cost barrier \footnote{https://openai.com/pricing}. We utilise readily accessible models, which are open-source, and can be conveniently downloaded from Hugging Face \cite{wolf-etal-2020-transformers} in our experiments. By using open-source LLMs we aim for easy extensibility by other researchers and affordability for public bodies and businesses implementing sensitivity classification. Furthermore, many modern generative LLMs, such as GPT-4, use a decoder-only transformer architecture. Therefore, we have explored open-source decoder-only LLMs, including Meta’s Llama-2 \cite{touvron2023llama}, and the Mistral models (Mistral \cite{jiang2023mistral} and Mixtral \cite{jiang2024mixtral}). Furthermore, these generative models have been instruction fine-tuned, meaning they respond better to answering instructions, shown by other NLP tasks \cite{}[CITE (multiple)]. Our prompt engineering techniques are focused instructions, enabling these models to respond more effectively to queries about our sensitivity classification task.

Preliminary analysis exploring the knowledge these pre-trained LLMs (PLMs) possess regarding sensitive personal information is demonstrated through a concise question answering (QA) experiment. To assess our models’ understanding, we posed queries such as ‘What does sensitive personal information mean?’, ‘Describe FOIA Exemption 6’ (US), and ‘Describe UK FOIA Section 40’. The models effectively generated responses explaining the laws and regulations designed to safeguard sensitive personal information, such as the GDPR in Europe. Models also generated examples of protected attributes, including financial and health information, biometric and location data, as well as personal characteristics like race and religion. The models' ability to produce contextually appropriate information based on their training data indicates a foundational understanding of sensitive personal information. This understanding gives us confidence in their application for our purposes of sensitivity review.

\section{Prompt Engineering for Sensitive Personal Information/Prompting Strategies}
[maybe sub section of task]
Prompt engineering is used to steer the model into being suitable for a task that is not necessarily the goal of initial fine-tuning objectives. PLMs possess an extensive (English) vocabulary, and research indicates that these models, when appropriately prompted, can effectively identify and categorise documents for tasks like sentiment analysis \cite{kocon2023chatgpt, krugmann2024sentiment}. Moreover, prompts can influence the role or character the model assumes.

We design our prompts to instruct the model to use its understanding of sensitive personal information and directly apply this knowledge to identifying sensitive information within the email message. This allows the model to classify a document as sensitive or non-sensitive, similar to how a human reviewer would conduct a sensitivity review to protect sensitive content. Additionally, we can apply extra details about the task and email collection in the prompt to provide context to the model.

For our Enron collection, emails are from company email addresses where there is an expectation of professionalism. We know that sensitive emails are represented by coarse genres purely personal and personal but in a professional context, and that we aim to perform a sensitivity review on this collection, which is suitable context to give our model to explain our task. As well as simply providing context, we can also use in-context (few-shot) learning which provides examples of personal sensitive information present in email messages. We also apply more complex reasoning via chain-of-thought prompts, which allows the model to describe the message before classifying the documents. This intermediary step serves as self-generated rationale, facilitating more reasoning before the generated classification/sensitivity prediction.
