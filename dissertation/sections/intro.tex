Freedom of information laws are used around the world to give individuals the legal right to access information held by public authorities. In the UK, the Freedom of Information Act 2000 (FOIA) \cite{FOIA:00} entitles individuals to submit a freedom of information (FOI) request to government departments, local authorities, universities, and other publicly funded bodies. However, some information is exempt from release \cite{FOIA:00}; containing sensitivities that should not be accessible by the public, such as personal information. Before any requested information is available, documents must be pruned to ensure sensitive information is not released.

The increasing volume of digital documents is making it less feasible to conduct a fully manual sensitivity review. To alleviate reviewers, sensitivity classifiers \cite{mcdonald2014towards, mcdonald2017enhancing, baron2022providing} and review systems \cite{narvala2022sensitivity} to assist the sensitivity review process have been implemented and analysed. However, experts in the sensitivity review process still struggle to navigate through all this digital content. National statistics show a growing number of delays in FOI request responses \cite{SG:23, ONS:23}. These delays damage relationships between public bodies and requesters, as limited access to information decreases the transparency of public bodies. The issues of navigating through potentially sensitive documents is likely to be exacerbated as digital archive collections expand, further challenging the feasibility of manual sensitivity review.

Therefore, technological advancements are necessary for protecting sensitive content and ensuring the sensitivity review process is more feasible than exhaustive manual (and technology-assisted) review. Despite this ideal reviewing tool, due to the importance of protecting sensitive information, all government documents reviewed in the foreseeable future will have some level of manual review \cite{TNA:16}. This is reasonable as there is uncertainty around classifiersâ€™ capabilities. Identifying more reliable classifiers is an ongoing task, and studies show more accurate and confident classifiers benefit reviewers; increasing their reviewing speed when used within a review system \cite{mcdonald2020accuracy}.

[Email collections are enormous, and lots of different communication is sent via this channel. Email documents are important in archive collections as they provide detailed insights into the development of ideas, offering perspective that can benefit other research [CITE]. Currently, many archives do not collect emails due to privacy concerns and the volume of documents in an email collection [23]. Companies may also collect emails to monitor breaches of company secrets. Tools must identify sensitive personal information and remove the email document to ensure individuals' privacy and security are maintained when exploring email collections. Therefore, we are motivated to investigate an approach that will perform sensitivity review by identifying sensitive personal information to protect sensitive documents.]


[More motivation of generative AI gap in sensitivity classification?]
%\subsection{Motivation}
With the increased use of generative AI dominating (reasoning-based) natural language understanding tasks in other domains \cite{qiu2020pre, adiwardana2020towards, roller2020recipes, openai2023gpt}, we aim to investigate the effectiveness of large language models (LLMs) in understanding and generating classifications and explanations concerning sensitive personal information within potentially sensitive documents. In 2023, Baron et al. proposed the first use of a LLM to identify and explain sensitive information under FOIA Exemption 5 (the deliberative process privilege) \cite{baron2023using}. Their approach uses the pre-trained LLM, ChatGPT-3.5 \cite{brown2020language}, and evaluates how prompt variations influence the model's responses for zero-shot learning. Our work aims extends the exploration of LLMs in sensitivity detection, specifically focusing on identifying sensitive personal information (exempt under FOIA Section 40) with generative LLMs, where to the best of our knowledge no research effort has been made. Our research aims to contribute to the ongoing advancement of these models, enhancing their capabilities in detecting sensitive personal information and facilitating automated sensitivity reviews.

There are multiple strategies to enhance the performance of LLMs. One method is finetuning, used to also enhance other neural models; however, this is very expensive for LLMs \cite{naveed2023comprehensive}. Furthermore, training datasets labelled with sensitivity annotations can be small or non-existent for some sensitive domains, resulting in weaker model tuning. Another recent strategy to improve the performance of LLMs is prompt engineering \cite{liu2023pre}. Prompt engineering aims to give pre-trained LLMs awareness of contextual nuances, emphasising focus to specific characteristics of the data. Successful research into zero-shot prompt engineering \cite{wei2023zero, kojima2022large} shows the potential for exploring this less resource-intensive prompting strategy when using LLMs to identify sensitive personal information.

%\subsection{Research Contributions}
This paper aims to show if generative LLMs can improve on current methods for identifying sensitive personal information, and the effect of prompt engineering for sensitivity classification with LLMs. By leveraging LLMs and prompt engineering techniques we aim to show the possibility of automatic classification of sensitive information. With feasible (accurate and efficient) approaches, the scalability of handling and protecting sensitive personal information can be improved. In this paper we present a novel use of pre-trained LLMs with prompt engineering techniques to identify sensitive personal information [STATE what models and prompts]. We process responses from LLMs to obtain the binary sensitivity classification (sensitive/non-sensitve) for documents from the SARA email test collection [CITE]. Our experiments show that generative LLMs classification performance is [RESULTS] traditional machine learning techniques. We also find that prompt engineering techniques can [RESULTS improve/effect the response quality of generative LLMs].

