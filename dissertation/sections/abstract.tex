Sensitive personal information is prevalent amongst documents within large collections that cannot be opened and made available without manual review to ensure the privacy and security of individuals. It would be beneficial to access the valuable information contained in these collections without infringing on privacy or confidentiality; however, the volume of context to review is too vast. This motivates the need for tools that can automatically identify and remove documents containing sensitive information. We propose a novel use of zero-shot learning with pre-trained LLMs that generate natural language to identify sensitive personal information, and explore prompt engineering strategies to enhance the performance of these models. We find pre-trained LLMs are not successful at classifying sensitive personal information given basic classification instructions; however, using our prompt engineering strategies these models produce statistically significant improvements in identifying sensitive personal information compared to our baseline prompting approach, where we obtain a balanced accuracy score of 0.6796 on our test collection.
